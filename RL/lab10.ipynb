{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright **`(c)`** 2023 Giovanni Squillero `<giovanni.squillero@polito.it>`  \n",
    "[`https://github.com/squillero/computational-intelligence`](https://github.com/squillero/computational-intelligence)  \n",
    "Free for personal or classroom use; see [`LICENSE.md`](https://github.com/squillero/computational-intelligence/blob/master/LICENSE.md) for details.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LAB10\n",
    "\n",
    "Use reinforcement learning to devise a tic-tac-toe player.\n",
    "\n",
    "### Deadlines:\n",
    "\n",
    "* Submission: Sunday, December 17 ([CET](https://www.timeanddate.com/time/zones/cet))\n",
    "* Reviews: Dies Natalis Solis Invicti ([CET](https://en.wikipedia.org/wiki/Sol_Invictus))\n",
    "\n",
    "Notes:\n",
    "\n",
    "* Reviews will be assigned  on Monday, December 4\n",
    "* You need to commit in order to be selected as a reviewer (ie. better to commit an empty work than not to commit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from itertools import permutations\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TicTacToe:\n",
    "    def __init__(self):\n",
    "        self.board = np.zeros((3, 3))\n",
    "        self.TICTACTOE_MAP = np.array([[1, 6, 5], [8, 4, 0], [3, 2, 7]])\n",
    "        self.player=1\n",
    "\n",
    "    def print_state(self):\n",
    "        for i in range(3):\n",
    "            for j in range(3):\n",
    "                if self.board[i, j] == 0:\n",
    "                    print(\"-\", end=\" \")\n",
    "                elif self.board[i, j] == 1:\n",
    "                    print(\"X\", end=\" \")\n",
    "                else:\n",
    "                    print(\"O\", end=\" \")\n",
    "            print()\n",
    "        print()\n",
    "        \n",
    "\n",
    "    def state(self):\n",
    "        return self.board\n",
    "    \n",
    "    def move(self, action):\n",
    "        if self.board[action] == 0:\n",
    "            self.board[action] = self.player\n",
    "            self.player = 3 - self.player\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    \n",
    "    def next_actions(self):\n",
    "        if self.check_win(1) or self.check_win(2):\n",
    "            return list()\n",
    "        row, columns = np.where(self.board == 0)\n",
    "        return list(zip(row, columns))\n",
    "    \n",
    "    def check_win(self, player):\n",
    "        cells = self.TICTACTOE_MAP[self.board == player]\n",
    "        return any(sum(h) == 12 for h in permutations(cells, 3))\n",
    "    \n",
    "    def reward(self, player):\n",
    "        if self.check_win(player):\n",
    "            return 1\n",
    "        elif self.check_win(3 - player):\n",
    "            return -1\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    def finished(self):\n",
    "        return len(self.next_actions()) == 0 or self.check_win(1) or self.check_win(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Qlearning:\n",
    "    def __init__(self, alpha, gamma, epsilon):\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.epsilon = epsilon\n",
    "        self.q_table = {}\n",
    "    \n",
    "    def set_epsilon(self, epsilon):\n",
    "        self.epsilon = epsilon\n",
    "        \n",
    "    def get_q_value(self, state, action):\n",
    "        if (state, action) not in self.q_table:\n",
    "            self.q_table[(state, action)] = 0\n",
    "        return self.q_table[(state, action)]\n",
    "    \n",
    "    def choice_action(self, state, actions):\n",
    "        if np.random.uniform() < self.epsilon:\n",
    "            return actions[np.random.choice(range(len(actions)))]\n",
    "        else:\n",
    "            q_values = np.array([self.get_q_value(state, action) for action in actions])\n",
    "            maximum = np.max(q_values)\n",
    "            return actions[np.random.choice(np.where(q_values == maximum)[0])]\n",
    "            \n",
    "    \n",
    "    def update(self, state, action, reward, next_state, next_actions):\n",
    "        q_value = self.get_q_value(state, action)\n",
    "        next_q_values = np.array([self.get_q_value(next_state, next_action) for next_action in next_actions])\n",
    "        maximum = np.max(next_q_values) if len(next_q_values) > 0 else 0\n",
    "        self.q_table[(state, action)] = q_value + self.alpha * (reward + self.gamma * maximum - q_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Policy For Player 1 ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 70000/70000 [02:05<00:00, 558.62it/s]\n"
     ]
    }
   ],
   "source": [
    "Q1 = Qlearning(0.5, 0.9, 1)\n",
    "games = 70000\n",
    "epsilon = np.linspace(1, 0.1, num=games, endpoint=True)\n",
    "\n",
    "for i in tqdm(range(games)):\n",
    "    Q1.set_epsilon(epsilon[i])\n",
    "    game = TicTacToe()\n",
    "\n",
    "    while not game.finished():\n",
    "        state = game.state().copy()\n",
    "        actions = game.next_actions()\n",
    "        action = Q1.choice_action(str(state), actions)\n",
    "        game.move(action)\n",
    "\n",
    "        if game.finished():\n",
    "            next_state = game.state().copy()\n",
    "            next_actions = game.next_actions()\n",
    "            reward = game.reward(1)\n",
    "            Q1.update(str(state), action, reward, str(next_state), next_actions)\n",
    "            \n",
    "        else:\n",
    "            reward = game.reward(1)\n",
    "            \n",
    "            actions_2 = game.next_actions()\n",
    "            action_2 = actions_2[np.random.choice(range(len(actions_2)))]\n",
    "            game.move(action_2)\n",
    "\n",
    "            if game.finished():\n",
    "                reward = game.reward(1)\n",
    "\n",
    "            next_state = game.state().copy()\n",
    "            next_actions = game.next_actions()\n",
    "            \n",
    "            Q1.update(str(state), action, reward, str(next_state), next_actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of wins: 99.2% \n",
      "Percentage of loses: 0.0% \n",
      "Percentage of ties: 0.8%\n"
     ]
    }
   ],
   "source": [
    "Q1.set_epsilon(0)\n",
    "win=0\n",
    "lose=0\n",
    "tie=0\n",
    "games=1000\n",
    "\n",
    "for i in range(games):\n",
    "    game = TicTacToe()\n",
    "    \n",
    "    while not game.finished():\n",
    "        if game.player == 1:\n",
    "            \n",
    "            state = game.state()\n",
    "            actions = game.next_actions()\n",
    "            action = Q1.choice_action(str(state), actions)\n",
    "            game.move(action)\n",
    "\n",
    "        else:\n",
    "            state = game.state()\n",
    "            actions = game.next_actions()\n",
    "            action = actions[np.random.choice(range(len(actions)))]\n",
    "            game.move(action)\n",
    "        \n",
    "        \n",
    "    if game.check_win(1):\n",
    "        win += 1\n",
    "    elif game.check_win(2):\n",
    "        lose += 1\n",
    "    else:\n",
    "        tie += 1\n",
    "\n",
    "print(f\"Percentage of wins: {win/games *100}% \\nPercentage of loses: {lose/games *100}% \\nPercentage of ties: {tie/games *100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Policy For Player 2 ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100000/100000 [02:36<00:00, 639.61it/s]\n"
     ]
    }
   ],
   "source": [
    "Q2 = Qlearning(0.5, 0.9, 1)\n",
    "games = 100000\n",
    "epsilon = np.linspace(1, 0, num=games, endpoint=True)\n",
    "\n",
    "for i in tqdm(range(games)):\n",
    "    Q2.set_epsilon(epsilon[i])\n",
    "    game = TicTacToe()\n",
    "     \n",
    "    actions_2 = game.next_actions()\n",
    "    action_2 = actions_2[np.random.choice(range(len(actions_2)))]\n",
    "    game.move(action_2)\n",
    "\n",
    "    while not game.finished():\n",
    "        state = game.state().copy()\n",
    "        actions = game.next_actions()\n",
    "        action = Q2.choice_action(str(state), actions)\n",
    "        game.move(action)\n",
    "\n",
    "        if game.finished():\n",
    "            next_state = game.state().copy()\n",
    "            next_actions = game.next_actions()\n",
    "            reward = game.reward(2)\n",
    "            Q2.update(str(state), action, reward, str(next_state), next_actions)\n",
    "            \n",
    "        else:\n",
    "            reward = game.reward(2)\n",
    "            \n",
    "            actions_2 = game.next_actions()\n",
    "            action_2 = actions_2[np.random.choice(range(len(actions_2)))]\n",
    "            game.move(action_2)\n",
    "\n",
    "            if game.finished():\n",
    "                reward = game.reward(2)\n",
    "\n",
    "            next_state = game.state().copy()\n",
    "            next_actions = game.next_actions()\n",
    "            \n",
    "            Q2.update(str(state), action, reward, str(next_state), next_actions)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of wins: 90.10000000000001% \n",
      "Percentage of loses: 0.6% \n",
      "Percentage of ties: 9.3%\n"
     ]
    }
   ],
   "source": [
    "Q2.set_epsilon(0)\n",
    "\n",
    "win=0\n",
    "lose=0\n",
    "tie=0\n",
    "\n",
    "games=1000\n",
    "for i in range(games):\n",
    "    game = TicTacToe()\n",
    "    while not game.finished():\n",
    "        if game.player == 2:\n",
    "            state = game.state()\n",
    "            actions = game.next_actions()\n",
    "            action = Q2.choice_action(str(state), actions)\n",
    "            game.move(action)\n",
    "        else:\n",
    "            state = game.state()\n",
    "            actions = game.next_actions()\n",
    "            action = actions[np.random.choice(range(len(actions)))]\n",
    "            game.move(action)\n",
    "    \n",
    "    if game.check_win(2):\n",
    "        win += 1\n",
    "    elif game.check_win(1):\n",
    "        lose += 1\n",
    "    else:\n",
    "        tie += 1\n",
    "\n",
    "print(f\"Percentage of wins: {win/games *100}% \\nPercentage of loses: {lose/games *100}% \\nPercentage of ties: {tie/games *100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Min-Max Experiment ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Qlearning:\n",
    "    def __init__(self, alpha, gamma, epsilon):\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.epsilon = epsilon\n",
    "        self.q_table = {}\n",
    "    \n",
    "    def set_epsilon(self, epsilon):\n",
    "        self.epsilon = epsilon\n",
    "        \n",
    "    def get_q_value(self, state, action):\n",
    "        if (state, action) not in self.q_table:\n",
    "            self.q_table[(state, action)] = 0\n",
    "        return self.q_table[(state, action)]\n",
    "    \n",
    "    def choice_action(self, state, actions, player):\n",
    "        if np.random.uniform() < self.epsilon:\n",
    "            return actions[np.random.choice(range(len(actions)))]\n",
    "        else:\n",
    "            q_values = np.array([self.get_q_value(state, action) for action in actions])\n",
    "            if player==1:\n",
    "                maximum = np.max(q_values)\n",
    "                return actions[np.random.choice(np.where(q_values == maximum)[0])]\n",
    "            \n",
    "            else:\n",
    "                minimum = np.min(q_values)\n",
    "                return actions[np.random.choice(np.where(q_values == minimum)[0])]\n",
    "            \n",
    "    \n",
    "    def update(self, state, action, reward, next_state, next_actions, player):\n",
    "        q_value = self.get_q_value(state, action)\n",
    "        next_q_values = np.array([self.get_q_value(next_state, next_action) for next_action in next_actions])\n",
    "        \n",
    "        if player==1:\n",
    "            maximum = np.max(next_q_values) if len(next_q_values) > 0 else 0\n",
    "            self.q_table[(state, action)] = q_value + self.alpha * (reward + self.gamma * maximum - q_value)\n",
    "        else:\n",
    "            minimum = np.min(next_q_values) if len(next_q_values) > 0 else 0\n",
    "            self.q_table[(state, action)] = q_value + self.alpha * (reward + self.gamma * minimum - q_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100000/100000 [05:15<00:00, 316.65it/s]\n"
     ]
    }
   ],
   "source": [
    "Q1 = Qlearning(0.5, 0.9, 1)\n",
    "games = 100000\n",
    "epsilon = np.linspace(1, 0, num=games, endpoint=True)\n",
    "\n",
    "for i in tqdm(range(games)):\n",
    "    Q1.set_epsilon(epsilon[i])\n",
    "    game = TicTacToe()\n",
    "\n",
    "    while not game.finished():\n",
    "        state = game.state().copy()\n",
    "        actions = game.next_actions()\n",
    "        action = Q1.choice_action(str(state), actions, game.player)\n",
    "        game.move(action)\n",
    "\n",
    "        next_state = game.state().copy()\n",
    "        next_actions = game.next_actions()\n",
    "        reward = game.reward(1)\n",
    "        Q1.update(str(state), action, reward, str(next_state), next_actions, game.player)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of wins: 96.5% \n",
      "Percentage of loses: 0.0% \n",
      "Percentage of ties: 3.5000000000000004%\n"
     ]
    }
   ],
   "source": [
    "Q1.set_epsilon(0)\n",
    "win=0\n",
    "lose=0\n",
    "tie=0\n",
    "games=1000\n",
    "\n",
    "for i in range(games):\n",
    "    game = TicTacToe()\n",
    "    \n",
    "    while not game.finished():\n",
    "        if game.player == 1:\n",
    "            \n",
    "            state = game.state()\n",
    "            actions = game.next_actions()\n",
    "            action = Q1.choice_action(str(state), actions, game.player)\n",
    "            game.move(action)\n",
    "\n",
    "        else:\n",
    "            state = game.state()\n",
    "            actions = game.next_actions()\n",
    "            action = actions[np.random.choice(range(len(actions)))]\n",
    "            game.move(action)\n",
    "        \n",
    "        \n",
    "    if game.check_win(1):\n",
    "        win += 1\n",
    "    elif game.check_win(2):\n",
    "        lose += 1\n",
    "    else:\n",
    "        tie += 1\n",
    "\n",
    "print(f\"Percentage of wins: {win/games *100}% \\nPercentage of loses: {lose/games *100}% \\nPercentage of ties: {tie/games *100}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ci-fLJ3OwGs-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
